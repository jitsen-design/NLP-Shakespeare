{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules, libraries and Shakespearean text for project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import urllib.request\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from textblob import TextBlob\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import gensim\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "Much_Ado = urllib.request.urlopen('http://www.textfiles.com/etext/AUTHORS/SHAKESPEARE/shakespeare-much-3.txt').read()\n",
    "Much_Ado_lines = Much_Ado.decode('utf8')\n",
    "Tempest = urllib.request.urlopen('http://www.textfiles.com/etext/AUTHORS/SHAKESPEARE/shakespeare-tempest-4.txt').read()\n",
    "Tempest_lines = Tempest.decode('utf8')\n",
    "Richard = urllib.request.urlopen('http://www.textfiles.com/etext/AUTHORS/SHAKESPEARE/shakespeare-tragedy-58.txt').read()\n",
    "Richard_lines = Richard.decode('utf8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce stopwords, including a corpus of Shakespearean stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "stop += ['|','[',']','And','Because','S','For','An','To','From','But','That','If','For','To','As'\n",
    "        'Than','Messenger','shall','must']\n",
    "stop += open('new_stop.txt','r').readlines()\n",
    "stop = [i.replace('\\n',\"\") for i in stop]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to clean text and separate by act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MySentences(Object):\n",
    "    vocab = []\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    Object = lemmatizer.lemmatize(Object[Object.find(\"ACT\"):])\n",
    "    for line in sent_tokenize(Object):\n",
    "        line = re.sub('[A-Z]{2,}',' ',line)\n",
    "        line = re.sub(\"\\[[^\\]]*\\]\",\"\",line)\n",
    "        line= re.sub('[%s]' % re.escape(string.punctuation), '', line)\n",
    "        vocab.append(line.split())\n",
    "    vocab_2 = [] \n",
    "    for i in vocab:\n",
    "        vocab_2.append(list(filter(lambda x: x not in stop, i)))\n",
    "    return vocab_2\n",
    "\n",
    "def Find_Acts(play):\n",
    "    play_Acts = {}\n",
    "    play_Acts2 = {}\n",
    "    i = 0\n",
    "    b = 0\n",
    "    for x in range(1,play.count('ACT')+1):\n",
    "        i = play.find(\"ACT\",+ b)\n",
    "        b = play.find(\"ACT\", i + 1)\n",
    "        play_Acts[x] = play[i:b]\n",
    "    for i in ['ACT I','ACT II','ACT III','ACT IV','ACT V']:\n",
    "        play_Acts2[i] = []\n",
    "    for k,v in play_Acts.items():\n",
    "        for i,j in play_Acts2.items():\n",
    "            if i in v.split('\\n'):\n",
    "                play_Acts2[i].append(v)\n",
    "    return play_Acts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jitsen/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  import sys\n",
      "/Users/jitsen/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Anne', 'ACT I', ['sister', 'Lo', 'presence', 'bottled', 'sin', 'vassal', 'snow', 'worship', 'mind', 'threat', 'imprisond', 'could', 'breaks', 'smoothing', 'suspect', 'lightly', 'wellspoken', 'reflecting', 'obstacles', 'forgive'], 0.17500000000000002), ('Anne', 'ACT II', [], 0), ('Anne', 'ACT III', [], 0), ('Anne', 'ACT IV', ['sister', 'Lo', 'tonguetied', 'bottled', 'sin', 'step', 'kingly', 'mind', 'could', 'pluck', 'ah', 'Whisper', 'benefit', 'haughty', 'George', 'A', 'mad', 'lets', 'revenge', 'blunt'], -0.625), ('Anne', 'ACT V', ['Lo', 'horses', 'shock', 'midst', 'snow', 'threat', 'mind', 'could', 'breaks', 'alacrity', 'George', 'A', 'mad', 'mount', 'fatherinlaw', 'frownd', 'revenge', 'oer', 'trembling', 'led'], -0.625)]\n"
     ]
    }
   ],
   "source": [
    "def gensim_model(play,Char):\n",
    "    most_similar_list = []\n",
    "    Act_list = ['ACT I','ACT II','ACT III','ACT IV','ACT V']\n",
    "    for i in Act_list:\n",
    "        try:\n",
    "            model = gensim.models.Word2Vec(MySentences(''.join(Find_Acts(play)[i])),size=100,min_count=1,workers=2)\n",
    "            most_similar_list.append((Char,i,[x[0] for x in model.most_similar(Char,topn=20)],\n",
    "                                 TextBlob(' '.join([x[0] for x in model.most_similar(Char,topn=20)])).sentiment[0]))\n",
    "        except: \n",
    "            most_similar_list.append((Char,i,[],0))\n",
    "    return most_similar_list\n",
    "print(gensim_model(Richard_lines,'Anne'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
